---
title: Caching Proxy for APIs
author: oskarjerzyk
keywords: tutorial
date: 2019-10-21
layout: tutorial
knotxVersions:
    - 2.0.0
---
# Overview
In this tutorial, we will use Knot.x as API gateway in order to show the usage of caching functionality. Knot.x will act as a proxy API to some external API and will cache it's responses.
The caching functionality can be implemented in a custom handler. Then we expose our custom handler in Open API specification. However, this approach requires development effort. But what if we would need to add a circuit breaker mechanism in future.

To fully understand this tutorial, it's highly recommended to get familiar with previous ones:
- [Getting started with Knot.x Stack](http://knotx.io/tutorials/getting-started-with-knotx-stack/2_0/)
- [Getting Started with Docker](http://knotx.io/tutorials/getting-started-with-docker/2_0/)
- [Configurable API gateway](http://knotx.io/tutorials/configurable-api-gateway/2_0/)

## Prerequisites
- JDK 8
- Docker
- Docker Swarm

## What you're going to learn:
- How to wrap an existing (target) API with caching proxy
- How to use [behaviours](https://github.com/Knotx/knotx-fragments/tree/2.0.0/handler#behaviours) and [actions](https://github.com/Knotx/knotx-fragments/tree/2.0.0/handler#actions)

Download the [Latest Knot.x Starter Kit release](https://github.com/Knotx/knotx-starter-kit/releases) and unzip it.

Project has the following structure:
```
├── docker
|   ├── Dockerfile                // Docker file with image definition.
├── functional                    // Keep here your functional tests. Example implementation included
├── gradle                        // Gradle wrapper and common gradle scripts
├── knotx/conf                    // Knotx configuration which will be copied to docker image
├── modules                       // Sub-modules of your project
│   ├── ...                       // example modules implementation
```

## Actions & behaviours
The first thing we are going to do, is to define our custom task which will properly handle our request. As explained in the previous tutorials,
Knot.x tasks are some kind of directed graphs consisting of actions (if you want to get more familiar with
configurable integrations please read [this](https://knotx.io/blog/configurable-integrations/) tutorial). Now, let's get it started 
and define our task

```hocon
tasks {
  api-task {
    action = fetch-product-with-cache
    onTransitions {
      _success {
        action = product-to-body
      }
    }
  }
}
```
As you see above, to achieve our goal we have to create only one task called `api-task` - this is very simple directed graph.
The action it performs is `fetch-product-with-cache` which we'll create soon. Then we have `onTransitions`, in our case let's 
define only `_success` - the action to be performed is `product-to-body`  which we'll also define.

```hocon
actions {
  fetch-product-with-cache {
    factory = in-memory-cache
    config {
      cache {
        maximumSize = 1000
        ttl = 5000
      }
      cacheKey = "product-{param.id}"
      payloadKey = fetch-product
    }
    doAction = fetch-product
  }

  product-to-body {
    factory = payload-to-body
    config {
      key = fetch-product
    }
  }

  fetch-product {
    factory = http
    config {
      endpointOptions {
        path = /product/id
        domain = webapi
        port = 8080
        allowedRequestHeaders = ["Content-Type"]
      }
    }
  }
}
```
Above you can see all necessary actions definitions. As mentioned before, we've created `fetch-product-with-cache`. The purpose 
of this action is to add cache functionality. Now you can see how easily we can define custom behaviours for our actions. 
We've just assigned to it `in-memory-cache` action factory, moreover this action also wraps other - in this case it's 
`fetch-product` - it's using simple http factory which will call desired endpoint - in our case `/product/id` (we'll define it later).
Finally we can focus on `product-to-body` - behaviour of this action is really simple - it's just adding previously fetched data
to response body.

Last thing to do here is to combine this two chunks of code into one file, let's call it `fragments-handler.conf ` and put it
inside `knotx/conf/routes/handlers/` directory.

## Why we need caching?
We've just added caching behaviour to action but you may wonder why we did it? Why we're using cache? The general purpose of
using caching is faster data retrieval - when user call the same endpoint for few times, we don't have to fetch data
from server for every request - we can cache it and reuse response (if not changed) in the future - it affects in quicker
response time, what is noticeable by the user. On the other hand, from server side it reduces latency and traffic. Requests
are satisfied in a shorter time with reused representations.

You may also wonder if we can replace this cache with another one, for example with Redis - yes you can do it very simple!
The only thing needed here is to create proper action factory which will handle desired cache and properly link it to action
in config file (the same way is we did above).

## Operations configuration
Now we have to configure `knotx/conf/routes/operations.conf`. In our config we should have define two operations:
- `healthcheck-operation`
- `product-api-caching-proxy-operation`

This operations are connected with `openapi.yaml` which we'll create next. This file specifies which handlers should be invoked 
to satisfy request. Now we'll focus on operation called `product-api-caching-proxy-operation` (it will be connected to `openapi.yaml`).
Below you can see file definition:

```hocon
routingOperations = ${routingOperations} [
  {
    operationId = product-api-caching-proxy-operation
    handlers = ${config.server.handlers.common.request} [
      {
        name = singleFragmentSupplier
        config = {
          type = json
          configuration {
            data-knotx-task = api-task
          }
        }
      },
      {
        name = fragmentsHandler
        config = {include required(classpath("routes/handlers/fragments-handler.conf"))}
      },

      {
        name = fragmentsAssembler
      }
    ] ${config.server.handlers.common.response}
  }
  {
    operationId = healthcheck-operation
    handlers = [
      {
        name = healthcheck
      }
    ]
  }
]
```
Regarding mentioned operation, we can see, that we're using three different handlers to perform it.
In our case, first handler to be called is `singleFragmentSupplier`. It's used to convert incoming http request
into `knotx-fragment` and assign `data-knotx-task` to it. Next to be called is `fragmentsHandler`, here we have to attach
additional configs with tasks specification. The last one is `fragmentsAssembler`
Purpose of using it, is to combine all fragments into final response. And this is all about operations.

## OpenAPI
Finally we can create `./knotx/conf/openapi.yaml`, it contains project-specific API definitions using the [OpenAPI 3.0 specification](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md) syntax. 
Let's fill it out with:
```yaml
openapi: "3.0.0"
info:
  version: 1.0.0
  title: API gateway caching example
  description: API gateway caching example

servers:
  - url: https://{domain}:{port}
    description: The local API server
    variables:
      domain:
        default: localhost
        description: api domain
      port:
        enum:
          - '8092'
        default: '8092'

paths:
  /healthcheck:
    get:
      operationId: healthcheck-operation
      responses:
        default:
          description: example vert.x healthcheck

  /product/id:
    get:
      operationId: product-api-caching-proxy-operation
      responses:
        default:
          description: Target API (Product API) caching proxy.
```
This is whole structure of this file required in our case. It was explained in more details in [this tutorial](http://knotx.io/tutorials/getting-started-with-knotx-stack/2_0/)  
The most important part here is `/product/id` endpoint definition. As you can see we are connecting this endpoint with
`product-api-caching-proxy-operation` which we've defined before.

We have all Knot.x specific files created, now we are gonna focus on project setup and deployment.  

## Project configuration
The first thing we need to do is to specify configuration files. Let's start in the project level directory and simply create `api-cache.yml`
This file is responsible for proper Docker configuration, in our case we are using Docker Swarm, therefore we have to configure
two images. Swarm is needed here because we need to expose external API (it's mocked by Wiremock in this case) and the API available for user.
Both are deployed in separate containers, therefore orchestrator is needed.
Let's specify the following configuration:
``` yml
version: '3.7'

networks:
  knotnet:

services:

  webapi:
    image: rodolpheche/wiremock
    volumes:
      - "./common-services/webapi:/home/wiremock"
    ports:
      - "3000:8080"
    networks:
      - knotnet

  knotx:
    image: knotx-example/api-cache:latest
    command: ["knotx", "run-knotx"]
    ports:
      - "8092:8092"
      - "18092:18092"
    networks:
      - knotnet
```

First and foremost it specifies Docker virtual network in which our services will be deployed. Then we have some service configs.
The first one is `webapi`
- `image` - docker image is provided here, 
- `volumes` - directories to which Docker will have access, in our case it's directory where all Wiremock configs are stored,
- `ports` - on the left side is provided port accessible from `localhost`, and on the right side we have port number available in virtual environment 
- `networks` - specifies in which docker network, service will be deployed.

Then we have `knotx` service specification, it's very similar to previous one, so only one property is worth to explain 
- `command` - this property is used to point Knot.x starting commands.

Next step in our configuration is to set `rootProject.name` in `settings.gradle.kts` (also at the project level directory),
also make sure that `healh-check` is included 
```gradle
rootProject.name = "api-cache"

include("health-check")

project(":health-check").projectDir = file("modules/health-check")
``` 

Next thing to do is to configure `gradle.properties` at project level directory. Let's fill it with
```gradle
version=2.0.0-SNAPSHOT
knotx.version=2.0.0
knotx.conf=knotx
docker.image.name=knotx-example/api-cache
```
Very important step here is to set `docker.image.name`, which is necessary to run proper docker image.

`build.gradle.kts` file could stay as it was provided with starterkit, we don't have to apply any modifications here.
The same if it comes to `./docker/Dockerfile`, version provided by default is absolutely enough for our purposes.

## Wiremock 
Wiremock is simply used for mocking server, we don't have to create real REST API, for our training purposes it's enough.
To do it let's create following directories on the project level directory:
- `common-services/webapi/__files/`
- `common-services/webapi/mappings/`

Into first directory please paste `product.json` file with following body:
```json
{
  "id": 21762532,
  "url": "http://knotx.io",
  "label": "Product"
}
```

And into second directory please paste `product.json` file with following body:
```json
{
  "request": {
    "method": "GET",
    "url": "/product/id"
  },
  "response": {
    "status": 200,
    "fixedDelayMilliseconds": 100,
    "bodyFileName": "product.json"
  }
}
```

Make sure that in `api-cache.yml` property `volume` properly points to `webapi` directory. And that's all about Wiremock.

## Build and run
From project level directory execute following commands which will build project and run Docker Swarm:
```shell script
$ gradlew clean build
$ docker swarm init
$ docker stack deploy -c api-cache.yml api-cache
```
After successful execution you should be able to see http response at [localhost:8092/product/id](localhost:8092/product/id)
